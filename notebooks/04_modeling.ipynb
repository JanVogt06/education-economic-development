{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Machine Learning: Vorhersage des BIP\n",
    "\n",
    "Dieses Notebook dokumentiert die Entscheidungen für das Machine Learning Modell.\n",
    "\n",
    "**Der Code befindet sich in:** `src/features/train_model.py`\n",
    "\n",
    "**Ausführung:** `python src/main.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ziel\n",
    "\n",
    "Wir wollen wissen: **Welche Bildungsfaktoren sind am wichtigsten für die Vorhersage des BIP pro Kopf?**\n",
    "\n",
    "Die Korrelationsanalyse in Notebook 03 hat uns paarweise Zusammenhänge gezeigt. Ein Machine Learning Modell kann uns zeigen, welche Features in Kombination am meisten zur Vorhersage beitragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entscheidung 1: Modellwahl\n",
    "\n",
    "### Random Forest Regressor\n",
    "\n",
    "Wir verwenden einen **Random Forest**, weil:\n",
    "\n",
    "1. **Feature Importance:** Random Forest liefert direkt die Wichtigkeit jedes Features\n",
    "2. **Nicht-lineare Zusammenhänge:** Kann komplexere Beziehungen erfassen als lineare Regression\n",
    "3. **Robust:** Weniger anfällig für Overfitting als einzelne Decision Trees\n",
    "\n",
    "Zum Vergleich trainieren wir auch eine **Lineare Regression** als Baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entscheidung 2: Features und Target\n",
    "\n",
    "### Target (y)\n",
    "\n",
    "**BIP pro Kopf, PPP** (`NY.GDP.PCAP.PP.CD`)\n",
    "\n",
    "PPP (Purchasing Power Parity) ist besser für Ländervergleiche geeignet, weil es die unterschiedlichen Preisniveaus berücksichtigt.\n",
    "\n",
    "### Features (X)\n",
    "\n",
    "| Feature | Code | Beschreibung |\n",
    "|---------|------|-------------|\n",
    "| Primärbildung | SE.PRM.ENRR | Einschulungsrate Grundschule (% brutto) |\n",
    "| Sekundarbildung | SE.SEC.ENRR | Einschulungsrate Sekundarstufe (% brutto) |\n",
    "| Tertiärbildung | SE.TER.ENRR | Einschulungsrate Hochschule (% brutto) |\n",
    "| Bildungsausgaben | SE.XPD.TOTL.GD.ZS | Bildungsausgaben (% des BIP) |\n",
    "\n",
    "Diese Features decken verschiedene Bildungsaspekte ab:\n",
    "- Verschiedene Bildungsstufen (Primär, Sekundär, Tertiär)\n",
    "- Investitionen in Bildung (Ausgaben)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entscheidung 3: Umgang mit fehlenden Werten\n",
    "\n",
    "### Problem\n",
    "\n",
    "Nicht alle Länder haben für alle Jahre vollständige Daten. Sklearn-Modelle können nicht mit NaN-Werten umgehen.\n",
    "\n",
    "### Lösung: SimpleImputer\n",
    "\n",
    "Wir verwenden `SimpleImputer(strategy=\"mean\")`.\n",
    "\n",
    "Fehlende Werte werden durch den Mittelwert der jeweiligen Spalte ersetzt. Das ist eine einfache, aber effektive Strategie für unseren Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entscheidung 4: Train/Test Split\n",
    "\n",
    "### Aufteilung\n",
    "\n",
    "- **80% Trainingsdaten** – zum Trainieren des Modells\n",
    "- **20% Testdaten** – zur Evaluation (das Modell hat diese Daten nie gesehen)\n",
    "\n",
    "### Warum?\n",
    "\n",
    "Wenn wir das Modell auf denselben Daten evaluieren, auf denen es trainiert wurde, überschätzen wir seine Leistung (Overfitting). Der Test-Score zeigt, wie gut das Modell auf neue, ungesehene Daten generalisiert.\n",
    "\n",
    "### Code\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "`random_state=42` sorgt für Reproduzierbarkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entscheidung 5: Pipeline\n",
    "\n",
    "Wir verwenden `make_pipeline` aus der Vorlesung (Session 14), um Imputation und Modell zu kombinieren:\n",
    "\n",
    "```python\n",
    "model = make_pipeline(\n",
    "    SimpleImputer(strategy=\"mean\"),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)\n",
    ")\n",
    "```\n",
    "\n",
    "### Vorteile\n",
    "\n",
    "1. **Kein Data Leakage:** Der Imputer wird nur auf Trainingsdaten gefittet\n",
    "2. **Sauberer Code:** Ein Objekt für den gesamten Workflow\n",
    "3. **Einfache Anwendung:** `model.fit()` und `model.predict()` machen alles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation: R²-Score\n",
    "\n",
    "### Was ist R²?\n",
    "\n",
    "Der R²-Score (Bestimmtheitsmaß) misst, wie viel der Varianz im Target durch das Modell erklärt wird:\n",
    "\n",
    "- **R² = 1.0** → Perfekte Vorhersage\n",
    "- **R² = 0.0** → Modell nicht besser als der Mittelwert\n",
    "- **R² < 0.0** → Modell schlechter als der Mittelwert\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Train R²:** Wie gut passt das Modell zu den Trainingsdaten?\n",
    "- **Test R²:** Wie gut generalisiert das Modell auf neue Daten?\n",
    "\n",
    "Ein großer Unterschied (Train >> Test) deutet auf Overfitting hin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Importance\n",
    "\n",
    "### Was ist Feature Importance?\n",
    "\n",
    "Random Forest berechnet, wie viel jedes Feature zur Vorhersage beiträgt. Features mit hoher Importance sind wichtiger für die Vorhersage.\n",
    "\n",
    "### Zugriff\n",
    "\n",
    "```python\n",
    "rf_model.feature_importances_\n",
    "```\n",
    "\n",
    "### Wichtig\n",
    "\n",
    "Feature Importance zeigt **Vorhersagekraft**, nicht **Kausalität**! Ein Feature kann wichtig für die Vorhersage sein, ohne das BIP direkt zu verursachen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Output\n",
    "\n",
    "Das Training (`python src/main.py`) erzeugt:\n",
    "\n",
    "| Datei | Beschreibung |\n",
    "|-------|-------------|\n",
    "| `models/random_forest.joblib` | Das trainierte Modell |\n",
    "| `models/feature_importance.csv` | Feature Importance Tabelle |\n",
    "\n",
    "Das Modell kann später mit `joblib.load()` geladen werden, um Vorhersagen zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Erwartete Ergebnisse\n",
    "\n",
    "Basierend auf den Korrelationsanalysen aus Notebook 03 erwarten wir:\n",
    "\n",
    "1. **Tertiärbildung** sollte die höchste Feature Importance haben (ρ = 0.77 mit BIP)\n",
    "2. **Sekundarbildung** sollte ebenfalls wichtig sein (ρ = 0.80 mit BIP)\n",
    "3. **Primärbildung** sollte wenig beitragen (ρ = 0.06 mit BIP)\n",
    "4. **Bildungsausgaben** könnten überraschen – trotz schwacher Korrelation (ρ = 0.26) könnte das Feature in Kombination mit anderen wichtig sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Einschränkungen\n",
    "\n",
    "1. **Nur Bildungsindikatoren:** Andere wichtige Faktoren (Politik, Geographie, Geschichte, Ressourcen) fehlen\n",
    "2. **Keine Kausalität:** Das Modell zeigt Zusammenhänge, keine Ursache-Wirkung\n",
    "3. **Imputation:** Fehlende Werte wurden durch Mittelwerte ersetzt – das kann die Ergebnisse verzerren\n",
    "4. **Panel-Daten:** Wir behandeln jede Land-Jahr-Kombination als unabhängige Beobachtung, obwohl Länder über Zeit korreliert sind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
